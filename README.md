# LinkedIn Insights Microservice

## ğŸ“Œ Overview
This microservice scrapes LinkedIn company pages and extracts insights such as company details, recent posts, and engagement metrics. It provides a RESTful API built with **FastAPI**, utilizes **MongoDB** for data storage, and supports **asynchronous processing** for efficient scraping.

---

## ğŸš€ Features
- **Scrape LinkedIn company pages**
- **Extract key insights** (company info, posts, engagement stats)
- **Store data in MongoDB**
- **FastAPI-based RESTful API** with endpoints for filtering and pagination
- **Redis integration (if applicable)** for caching
- **Support for environment variables (.env)**

---

## ğŸ— Project Structure
```
linkedin_insights_microservice/
â”‚-- app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ scraper.py   # Scraper API routes
â”‚   â”‚   â”‚   â”œâ”€â”€ page.py      # Page API routes
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ database.py      # MongoDB connection
â”‚   â”‚   â”œâ”€â”€ config.py        # Configuration settings
â”‚   â”œâ”€â”€ main.py              # FastAPI entry point
â”‚-- .env                      # Environment variables
â”‚-- requirements.txt          # Python dependencies
â”‚-- README.md                 # Project documentation
```

---

## âš™ï¸ Setup & Installation
### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/your-repo/linkedin_insights_microservice.git
cd linkedin_insights_microservice
```

### **2ï¸âƒ£ Create & Activate Virtual Environment**
```bash
python3 -m venv .venv
source .venv/bin/activate  # Mac/Linux
.venv\Scripts\activate     # Windows
```

### **3ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

### **4ï¸âƒ£ Set Up Environment Variables**
Create a `.env` file in the project root and add:
```
MONGO_URI=mongodb://localhost:27017
DATABASE_NAME=linked_microservice_insights
```

### **5ï¸âƒ£ Start the FastAPI Server**
```bash
uvicorn app.main:app --reload
```

The API will be available at: [http://localhost:8000](http://localhost:8000)

---

## ğŸ“¡ API Endpoints
### **1ï¸âƒ£ Scrape LinkedIn Company Page**
```http
POST /api/scraper/scrape
```
**Request Body:**
```json
{
  "url": "https://www.linkedin.com/company/microsoft",
  "type": "company"
}
```
**Response:**
```json
{
  "status": "success",
  "message": "Successfully scraped company page",
  "data": { ... }
}
```

### **2ï¸âƒ£ Fetch All Scraped Pages**
```http
GET /api/pages
```

### **3ï¸âƒ£ Fetch a Specific Page by ID**
```http
GET /api/pages/{page_id}
```

---

## ğŸ›  Debugging Common Issues
### **1ï¸âƒ£ Module Not Found: `database`**
- Ensure you are using **absolute imports** in `scraper.py`:
  ```python
  from app.core.database import pages_collection
  ```

### **2ï¸âƒ£ MongoDB Connection Issues**
- Ensure MongoDB is running:
  ```bash
  mongod --dbpath /path/to/data/db
  ```
- Verify your `.env` file has the correct `MONGO_URI`

### **3ï¸âƒ£ Server Not Starting (`Address already in use`)**
- Kill the existing process using port 8000:
  ```bash
  lsof -i :8000  # Find process ID
  kill -9 <PID>  # Kill process
  ```

---

## ğŸ“œ License
This project is licensed under the **MIT License**.

---

## ğŸ¤ Contributing
Contributions are welcome! Feel free to open issues or submit pull requests.

Happy coding! ğŸš€